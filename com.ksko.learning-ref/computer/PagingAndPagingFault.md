# 다중 단계 페이징 시스템 (다중 계층 페이징)

페이징 테이블을 여러 단계로 나눠 (3,4) 메모리 낭비를 줄인다.  
예를 들어, 32비트의 시스템이라면 page directory(10bit), page table(10bit0, offset(12bit) 로 나눈다.  
  
## TLB
  
페이지테이블에 저장된 물리메모리 주소를 캐시하고 있는 곳이다. CPU에서 MMU에 데이터를 요청할 때, 
  
1. 물리메모리의 페이지 테이블로 접근해서 물리주소를 받아온다.(CR3)
2. 가져온 물리주소로 다시 물리메모리에 접근해, 데이터를 CPU에 전달한다.  
  
와 같이 두 단계를 거친다. 그러나 TLB가 1번의 과정을 거쳐 받아온 물리주소를 캐시하고 있으면 CPU는 바로 해당 물리주소로 접근하면 되어서 속도를 증가시킬 수 있다.  
  
## 공유 메모리
여러 프로세스가 **같은** 물리주소를 가리킨다.  
  
여기서 내가 잠깐 헷갈렸던 것!  
1. 프로세스가 커널 메모리를 가지고 있다??
	: 모든 프로세스는 자신만의 가상 주소 공간을 가진다. 각 비트 수에 맞게 4,16GB를 가지는데 이 프로세스에 커널 메모리가 유효하다. 
	
이어서, 같은 물리주소를 가리키므로 아까 위에서 찾아봤듯 모든 프로세스가 가질 커널 메모리는 공유메모리로서 같은 주소를 가진다.  
단, 공유메모리에 쓰기 작업을 할 경우 공간을 복사해서 각 프로세스의 페이지 테이블의 주소값을 변경한다.  
  
## 페이지 폴트
페이징을 하는 방법에는 두 가지가 있다.  
1. 요구 페이징 (Demand Paging) : 모든 데이터를 적재하지 않고, 필요한 시점에 필요한 것을 적재한다.
2. 선행 페이징 : 데이터를 미리 메모리에 올려두고 실행한다.  
  
위의 두 방법은 서로 상반된다.  
요구 페이징에서 데이터를 적재하기 이전에 데이터가 있는지 확인하는 과정에서 일어나는 것이 **페이지 폴트 인터럽트** 이다.  
  
위에 TLB 에서 설명한 단계 중에서 페이지 테이블에 물리주소를 가지러 갈 때  
1. valid-invalid bit를 확인하니 유효하지 않다! -> 페이지 폴트 인터럽트 발생!!  
2. OS는 저장매체(하드디스크나..)에서 데이터를 확인한다.  
3. 필요한 데이터를 물리메모리에 업로드한다.  
4. valid-invalid bit를 유효로 변경한다.
5. 재요청을 요청한다.
6. CPU는 재요청을 한다.  
  
의 과정이 일어난다. 이는 여러 과정을 요하기 때문에 시간이 오래 걸리므로 유의해야한다.
